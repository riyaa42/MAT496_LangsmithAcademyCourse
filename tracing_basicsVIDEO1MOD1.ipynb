{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instead of OPENAI I've changed the code to use my Gemini API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set your environment variables, including your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"C:/Users/Lenovo/Documents/code/mat496/.env\", override=True) #path to my .env file with given variables INCLUDING GEMINI API KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing with @traceable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The @traceable decorator is a simple way to log traces from the LangSmith Python SDK. Simply decorate any function with @traceable.\n",
    "\n",
    "The decorator works by creating a run tree for you each time the function is called and inserting it within the current trace. The function inputs, name, and other information is then streamed to LangSmith. If the function raises an error or if it returns a response, that information is also added to the tree, and updates are patched to LangSmith so you can detect and diagnose sources of errors. This is all done on a background thread to avoid blocking your app's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core>=0.3.75 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.3.76)\n",
      "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-google-genai) (2.10.3)\n",
      "Collecting filetype<2,>=1.2 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading google_api_core-2.25.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.3)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.32.3)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading grpcio-1.75.1-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.12.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.28)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.0)\n",
      "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.2-py3-none-any.whl (162 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.75.1-cp313-cp313-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 4.2/4.6 MB 20.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 16.6 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.75.1-py3-none-any.whl (14 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: filetype, rsa, protobuf, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-api-core, google-ai-generativelanguage, langchain-google-genai\n",
      "\n",
      "   --- ------------------------------------  1/11 [rsa]\n",
      "  Attempting uninstall: protobuf\n",
      "   --- ------------------------------------  1/11 [rsa]\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "   --- ------------------------------------  1/11 [rsa]\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "   --- ------------------------------------  1/11 [rsa]\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "   --- ------------------------------------  1/11 [rsa]\n",
      "   ------- --------------------------------  2/11 [protobuf]\n",
      "   ------- --------------------------------  2/11 [protobuf]\n",
      "   ------- --------------------------------  2/11 [protobuf]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   -------------- -------------------------  4/11 [proto-plus]\n",
      "   ------------------ ---------------------  5/11 [googleapis-common-protos]\n",
      "   ------------------ ---------------------  5/11 [googleapis-common-protos]\n",
      "   ------------------ ---------------------  5/11 [googleapis-common-protos]\n",
      "   --------------------- ------------------  6/11 [google-auth]\n",
      "   --------------------- ------------------  6/11 [google-auth]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ---------------------------------------- 11/11 [langchain-google-genai]\n",
      "\n",
      "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.7.0 google-api-core-2.25.2 google-auth-2.41.1 googleapis-common-protos-1.70.0 grpcio-1.75.1 grpcio-status-1.75.1 langchain-google-genai-2.1.12 proto-plus-1.26.1 protobuf-6.32.1 rsa-4.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_vector_db_retriever\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m MODEL_PROVIDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle\u001b[39m\u001b[38;5;124m\"\u001b[39m                       \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import langchain_google_genai\n",
    "from langsmith import traceable\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "# Configuration\n",
    "MODEL_PROVIDER = \"google\"                       \n",
    "MODEL_NAME = \"gemini-2.5-flash\"                \n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "If you don't know the answer, just say that you don't know. Use bullet points and other formatting methods where needed.\n",
    "You can make logical assumptions/deductions from provided context but do not assume any other information\n",
    "\"\"\"\n",
    "\n",
    "# Initialize\n",
    "\n",
    "# The system prompt is passed here as per langchain specifications\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=MODEL_NAME, \n",
    "    temperature=0.3,\n",
    "    max_tokens=1024,\n",
    "    system_instruction=RAG_SYSTEM_PROMPT \n",
    ")\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever() # Assumed retriever initialization\n",
    "\n",
    "# Traced Functions TODO DONE\n",
    "\n",
    "@traceable(metadata={\"vectordb\": \"sklearn\"})\n",
    "def retrieve_documents(question: str):\n",
    "    \"\"\"Retrieves documents using the vector store retriever.\"\"\"\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable\n",
    "def generate_response(question: str, documents):\n",
    "    \"\"\"Prepares documents and calls the model for generation.\"\"\"\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    " \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return call_gemini(messages)\n",
    "\n",
    "@traceable(\n",
    "    \n",
    "    metadata={\"model_name\": MODEL_NAME, \"model_provider\": MODEL_PROVIDER}\n",
    ")\n",
    "def call_gemini(\n",
    "    messages: List[dict]\n",
    ") -> str:\n",
    "    \"\"\"Call Google's Gemini API via the pre-initialized LangChain Chat Model.\"\"\"\n",
    "    \n",
    "    # We use the pre-initialized 'llm' object which holds the model and system prompt config\n",
    "    response = llm.invoke(messages) \n",
    "    \n",
    "    return response.content\n",
    "\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    \"\"\"The full RAG pipeline entry point.\"\"\"\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@traceable handles the RunTree lifecycle for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I trace with the @traceable decorator?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith supports sending arbitrary metadata along with traces.\n",
    "\n",
    "Metadata is a collection of key-value pairs that can be attached to runs. Metadata can be used to store additional information about a run, such as the version of the application that generated the run, the environment in which the run was generated, or any other information that you want to associate with a run. Similar to tags, you can use metadata to filter runs in the LangSmith UI, and can be used to group runs together for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(\n",
    "    # TODO: Add Metadata\n",
    "    # metadata={\"vectordb\": \"sklearn\"}\n",
    ")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "@traceable(\n",
    "    # TODO: Add Metadata\n",
    "    # metadata={\"model_name\": MODEL_NAME, \"model_provider\": MODEL_PROVIDER}\n",
    ")\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I add Metadata to a Run with @traceable?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add metadata at runtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I add metadata at runtime?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"runtime_metadata\": \"foo\"}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
